{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "d__3nTExoCEu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doub_conv(in_c,out_c):\n",
        "  conv = nn.Sequential(nn.Conv2d(in_c,out_c,kernel_size = 3),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Conv2d(out_c,out_c,kernel_size = 3),\n",
        "                       nn.ReLU())\n",
        "  return conv"
      ],
      "metadata": {
        "id": "GDoShXEspz-t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_transpose(in_c,out_c):\n",
        "  conv_tr = nn.ConvTranspose2d(in_c,out_c,kernel_size = 2,stride = 2)\n",
        "\n",
        "  return conv_tr"
      ],
      "metadata": {
        "id": "7IBgQDSWzMyw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "oxcx-JsG_bSz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "SEo4vgA_n3Aw"
      },
      "outputs": [],
      "source": [
        "class UNetModel(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
        "    self.down_conv1 = doub_conv(1,64)\n",
        "    self.down_conv2 = doub_conv(64,128)\n",
        "    self.down_conv3 = doub_conv(128,256)\n",
        "    self.down_conv4 = doub_conv(256,512)\n",
        "    self.down_conv5 = doub_conv(512,1024)\n",
        "\n",
        "    self.tr_conv1 = conv_transpose(1024,512)\n",
        "    self.tr_conv2 = conv_transpose(512,256)\n",
        "    self.tr_conv3 = conv_transpose(256,128)\n",
        "    self.tr_conv4 = conv_transpose(128,64)\n",
        "\n",
        "    self.crop1 = transforms.CenterCrop((392,392))\n",
        "    self.crop2 = transforms.CenterCrop((200,200))\n",
        "    self.crop3 = transforms.CenterCrop((104,104))\n",
        "    self.crop4 = transforms.CenterCrop((56,56))\n",
        "\n",
        "    self.up_conv1 = doub_conv(1024,512)\n",
        "    self.up_conv2 = doub_conv(512,256)\n",
        "    self.up_conv3 = doub_conv(256,128)\n",
        "    self.up_conv4 = doub_conv(128,64)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,image):\n",
        "    x1 = self.down_conv1(image)\n",
        "    x2 = self.max_pool(x1)\n",
        "    x3 = self.down_conv2(x2)\n",
        "    x4 = self.max_pool(x3)\n",
        "    x5 = self.down_conv3(x4)\n",
        "    x6 = self.max_pool(x5)\n",
        "    x7 = self.down_conv4(x6)\n",
        "    x8 = self.max_pool(x7)\n",
        "    x9 = self.down_conv5(x8)\n",
        "    x10 = self.tr_conv1(x9)\n",
        "    x11 = self.up_conv1(torch.cat([x10,self.crop4(x7)],dim=1))\n",
        "    x12 = self.up_conv2(torch.cat([self.tr_conv2(x11),self.crop3(x5)],dim = 1))\n",
        "    x13 = self.up_conv3(torch.cat([self.tr_conv3(x12),self.crop2(x3)],dim = 1))\n",
        "    x14 = self.up_conv4(torch.cat([self.tr_conv4(x13),self.crop1(x1)],dim = 1))\n",
        "\n",
        "    final_output = nn.Conv2d(64,2,kernel_size = 1)\n",
        "    return final_output(x14)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  image = torch.rand((1,1,572,572))\n",
        "  model = UNetModel()\n",
        "  print(model(image)   )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_kDsgypxup1",
        "outputId": "d1958f39-e3de-4761-be5f-2d7ea28229b5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.0767, -0.0769, -0.0771,  ..., -0.0796, -0.0796, -0.0777],\n",
            "          [-0.0756, -0.0776, -0.0775,  ..., -0.0776, -0.0783, -0.0773],\n",
            "          [-0.0785, -0.0788, -0.0779,  ..., -0.0773, -0.0742, -0.0751],\n",
            "          ...,\n",
            "          [-0.0781, -0.0787, -0.0771,  ..., -0.0775, -0.0778, -0.0778],\n",
            "          [-0.0784, -0.0774, -0.0784,  ..., -0.0765, -0.0746, -0.0778],\n",
            "          [-0.0804, -0.0772, -0.0753,  ..., -0.0777, -0.0799, -0.0765]],\n",
            "\n",
            "         [[ 0.0420,  0.0432,  0.0448,  ...,  0.0417,  0.0413,  0.0424],\n",
            "          [ 0.0428,  0.0478,  0.0422,  ...,  0.0432,  0.0459,  0.0396],\n",
            "          [ 0.0438,  0.0461,  0.0467,  ...,  0.0408,  0.0443,  0.0454],\n",
            "          ...,\n",
            "          [ 0.0444,  0.0400,  0.0428,  ...,  0.0434,  0.0422,  0.0424],\n",
            "          [ 0.0412,  0.0434,  0.0420,  ...,  0.0418,  0.0410,  0.0446],\n",
            "          [ 0.0440,  0.0415,  0.0434,  ...,  0.0454,  0.0438,  0.0422]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tm3HXaJFxL0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}